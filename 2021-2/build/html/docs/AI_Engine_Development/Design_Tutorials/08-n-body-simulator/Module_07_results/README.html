
<table class="sphinxhide" width="100%">
<tr width="100%">
<td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/>
<a href="https://www.xilinx.com/products/design-tools/vitis.html">See Vitis™ Development Environment on xilinx.com</a>
<a href="https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html">See Vitis-AI™ Development Environment on xilinx.com</a>
</td>
</tr>
</table>
<p>You can create a gif from your own <code class="docutils literal notranslate"><span class="pre">data/animation_data.txt</span></code> file using the following command:</p>
<p><em>Estimated time: 3 minutes</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">animation</span>
</pre></div>
</div>
<h2>Results</h2>
<p>The following is a GIF created from the <code class="docutils literal notranslate"><span class="pre">data/animation_data_golden.txt</span></code> file. You should get a similar GIF from your own data.</p>
<h3>12,800 Particles Simulated on a 400 tile AI Engine Accelerator for 300 Timesteps</h3>
<p><img alt="alt text" src="../../../../../_images/animation.gif"/></p>
<h2>Latency Performance Comparisons</h2>
<p>Following is a table comparing the executions times to simulate 12,800 particles for one timestep on the different N-Body Simulators explored in this tutorial.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Name</th>
<th>Hardware</th>
<th>Algorithm</th>
<th>Average Execution Time for 1 Timestep (seconds)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python NBody Simulator</td>
<td>x86 Linux Machine</td>
<td>O(N)</td>
<td>14.96</td>
</tr>
<tr>
<td>C++ NBody Simulator</td>
<td>A72 Embedded Arm Processor</td>
<td>O(N<sup>2</sup>)</td>
<td>124.79</td>
</tr>
<tr>
<td>AI Engine NBody Simulator</td>
<td>Versal AI Engine IP</td>
<td>O(N)</td>
<td>0.004657468</td>
</tr>
</tbody>
</table><p>As you can see, the N-Body Simulator implemented on the AI Engine offers a x2,800 improvement over the Python O(N) implementation and a x24,800 improvement over the C++ O(N<sup>2</sup>) implementation. A vectorized C++ NBody Simulator O(N) implementation can be created with pthreads, but is left as an exercise for the user.</p>
<h2>Design Throughput Calculations (Effective vs. Theoretical)</h2>
<p>The following table describes the total number of floating-point operations (FLOP) for 1 iteration of a single <code class="docutils literal notranslate"><span class="pre">nbody()</span></code> AI Engine kernel:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Section of Code</th>
<th>mac</th>
<th>mul</th>
<th>add</th>
<th>sub</th>
<th>invsqr</th>
<th>Total FLOP</th>
</tr>
</thead>
<tbody>
<tr>
<td>Step 1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>Step 2</td>
<td>96</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>192</td>
</tr>
<tr>
<td>Step 3</td>
<td>2,470,400</td>
<td>1,228,800</td>
<td>51,200</td>
<td>1,228,800</td>
<td>3,276,800</td>
<td>10,726,400</td>
</tr>
</tbody>
</table><p><strong>Note: Each section is clearly commented in the <code class="docutils literal notranslate"><span class="pre">nbody.cc</span></code> source file.</strong></p>
<p><strong>Note: To calculate the total, each <code class="docutils literal notranslate"><span class="pre">mac</span></code> is considered 2 operations (<code class="docutils literal notranslate"><span class="pre">mul</span></code> and <code class="docutils literal notranslate"><span class="pre">add</span></code>).</strong></p>
<p>Thus, each <code class="docutils literal notranslate"><span class="pre">nbody()</span></code> kernel executes ~10.7 million FLOP/iteration. Since we have 400 AI Engine tiles (i.e. 400 <code class="docutils literal notranslate"><span class="pre">nbody()</span></code> kernels) that execute simulatenously, the total number for the entire AI Engine array becomes ~4.2 billion FLOP/iteration. We calculated each iteration of the entire design (including data movement from DDR to AI Engine) takes an average of 0.004657468 seconds. <strong>Therefore the effective throughput of the entire design is ~921.2 GFLOP/s</strong>.</p>
<p>The theoretical peak throughput the AI Engine array alone can acheive is ~8 Tera FLOP/s, and we’re only using 1/10th of its potential!</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Effective Throughput</th>
<th>Theoretical Peak Throughput</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9212 TFLOP/s</td>
<td>8 TFLOP/s</td>
</tr>
</tbody>
</table><p>This design of an N-Body Simulator on the AI Engine is a straightforward implementation without any major optimizations done. To further maximize the throughput of the entire design:</p>
<ul class="simple">
<li><p>you can explore increasing <code class="docutils literal notranslate"><span class="pre">FMAX</span></code> of the PL kernels from 200 MHz to closer to 500 MHz to reduce the latency of moving data from DDR to the AI Engine</p></li>
<li><p>PL kernels currently implement a round-robin method of transmitting data. They could be designed to cache and schedule in an optimized way to increate data bandwidth</p></li>
<li><p>you can refactor the <code class="docutils literal notranslate"><span class="pre">nbody()</span></code> kernel to reduce its reliance on the scalar processor and only use the vector processor in each AI Engine tile by approximating inverse square root</p></li>
</ul>
<h2>(Optional) Building x1_design and x10_design</h2>
<p>What has been presented so far is the 100 compute unit AI Engine design utilizing all 400 AI Engine tiles. However, to get there you had to create the intermediate AI Engine designs that contain a single compute unit (4 tiles) and 10 compute units (40 tiles). If you wish to run the <code class="docutils literal notranslate"><span class="pre">aiesimulator</span></code>, hardware emulation, or build an AI Engine NBody Simulator with significantly shorter build times, feel free to build the <code class="docutils literal notranslate"><span class="pre">x1_design</span></code> or <code class="docutils literal notranslate"><span class="pre">x10_design</span></code>.</p>
<h3>Building the x1_design (simulates 128 particles)</h3>
<p><em>Estimated time: 1 hour</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">x1_design</span>
<span class="n">make</span> <span class="nb">all</span> <span class="n">TARGET</span><span class="o">=&lt;</span><span class="n">hw</span><span class="o">|</span><span class="n">hw_emu</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>128 particles simulated for 300 timesteps</p>
<p><img alt="alt text" src="../../../../../_images/animation1.gif"/></p>
<h4>Building the x10_design (simulates 1,280 particles)</h4>
<p><em>Estimated time: 1 hour</em></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">x10_design</span>
<span class="n">make</span> <span class="nb">all</span> <span class="n">TARGET</span><span class="o">=&lt;</span><span class="n">hw</span><span class="o">|</span><span class="n">hw_emu</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>1,280 particles simulated for 300 timesteps</p>
<p><img alt="alt text" src="../../../../../_images/animation2.gif"/></p>
<p>GitHub issues will be used for tracking requests and bugs. For questions go to <a class="reference external" href="http://support.xilinx.com/">support.xilinx.com</a>.</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License.</p>
<p>You may obtain a copy of the License at <a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>
<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>
<p align="center"> XD068 | © Copyright 2021 Xilinx, Inc.</p>
<footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>
